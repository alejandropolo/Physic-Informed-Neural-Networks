{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10767fd50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import importlib\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "sys.path.append('../Scripts/')\n",
    "import PINN_moredim\n",
    "import data\n",
    "\n",
    "importlib.reload(PINN_moredim)\n",
    "importlib.reload(data)\n",
    "from PINN_moredim import PINN_inference, DiffEquation\n",
    "from data import (\n",
    "    load_data_ode,\n",
    "    load_data_pde,\n",
    "    load_data_neumann,\n",
    "    load_data_moredim,\n",
    "    load_csv_data,\n",
    ")\n",
    "\n",
    "# from train import train\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Load the YAML file\n",
    "with open('../Config/config_pde_2d_robin.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Automatically create variables from the YAML keys\n",
    "for key, value in config.items():\n",
    "    for k, v in value.items():\n",
    "        globals()[k] = v\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equation and Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "diff_equation = DiffEquation(equation=equation, func_to_optimize=func_to_optimize, hidden_layers=[300, 100], activation='sigmoid')\n",
    "\n",
    "diff_equation.set_constants(constant_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep in mind that when using neumann, you have to define the solution in the PINN_moredim.py file\n",
    "bc_type = 'diri'\n",
    "if diff_equation.dx:\n",
    "    for eq in initial_conditions:\n",
    "        if 'ud' in eq:\n",
    "            bc_type = 'neumann'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_from_csv:\n",
    "    data = load_csv_data(diff_equation, data_from_csv, params_to_optimize=params_to_optimize)\n",
    "else:\n",
    "    if diff_equation.dx: # If PDE\n",
    "\n",
    "        if diff_equation.dy: # 2D\n",
    "            data = load_data_moredim(diff_equation, f, params_to_optimize=params_to_optimize, L=L, T=T, plate_length=plate_length, max_iter_time=max_iter_time)\n",
    "\n",
    "        elif bc_type == 'neumann': # Neumann BC\n",
    "            data = load_data_neumann(diff_equation, f, params_to_optimize, L_min, L, T, N_train)\n",
    "\n",
    "        else: # Dirichlet BC\n",
    "            data = load_data_pde(diff_equation, params_to_optimize=params_to_optimize, L_min=L_min, L=L, T=T, N_train=N_train, N_test=N_test, initial_conditions=initial_conditions)\n",
    "    \n",
    "    else: # If ODE\n",
    "        data = load_data_ode(diff_equation, params_to_optimize=params_to_optimize, initial_conditions=initial_conditions, t_0=t_0, t_fin=t_fin, n_points=n_points, noise=noise)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.manual_seed(42)\n",
    "# Inicializar los modelos y el optimizador\n",
    "pinn_inf_model = PINN_inference(params=params_to_optimize, input_size=data[2].shape[1], hidden_layers=layers, activation=activations, bc_type=bc_type, data_from_csv=data_from_csv).to(DEVICE)\n",
    "# pinn_inf_model = PINN_inference(params=params_to_optimize, input_size=data[2].shape[1], hidden_layers=layers, activation=activations, bc_type=bc_type).to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LBFGS\n",
      "Epoch: 0, Loss: 7.995114803314209, MSE Loss: 0.020733792334794998, Physics Loss: 0.0011269866954535246, Validation Loss: 0.13825318217277527 Boundary Loss:7.636918067932129\n",
      "Epoch: 30, Loss: 4.218235492706299, MSE Loss: 0.2837536633014679, Physics Loss: 0.016049090772867203, Validation Loss: 0.5063821077346802 Boundary Loss:3.2893059253692627\n",
      "Epoch: 60, Loss: 0.18308880925178528, MSE Loss: 0.02651691623032093, Physics Loss: 0.04356475546956062, Validation Loss: 0.018059683963656425 Boundary Loss:0.07903677225112915\n",
      "Epoch: 90, Loss: 0.04380396753549576, MSE Loss: 0.005184633657336235, Physics Loss: 0.014860033057630062, Validation Loss: 0.003258872078731656 Boundary Loss:0.018226217478513718\n",
      "Epoch: 120, Loss: 0.022839955985546112, MSE Loss: 0.0009445296018384397, Physics Loss: 0.008175988681614399, Validation Loss: 0.0006425085593946278 Boundary Loss:0.013154828920960426\n",
      "Epoch: 150, Loss: 0.017909908667206764, MSE Loss: 0.0005858114454895258, Physics Loss: 0.00626036012545228, Validation Loss: 0.0003562763740774244 Boundary Loss:0.010514259338378906\n",
      "Epoch: 180, Loss: 0.015932664275169373, MSE Loss: 0.0005690742982551455, Physics Loss: 0.006332609336823225, Validation Loss: 0.00033837687806226313 Boundary Loss:0.00825749896466732\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mpinn_inf_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiff_equation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiff_equation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstant_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiff_equation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstants\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_conditions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_conditions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlambda_pin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda_pin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlambda_ic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda_ic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlambda_bc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda_bc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m constant \u001b[38;5;129;01min\u001b[39;00m pinn_inf_model\u001b[38;5;241m.\u001b[39mparams:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(constant, \u001b[38;5;28mgetattr\u001b[39m(pinn_inf_model, constant)\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/Documents/Physic-Informed-Neural-Networks/Notebooks/../Scripts/PINN_moredim.py:854\u001b[0m, in \u001b[0;36mPINN_inference.train\u001b[0;34m(self, data, diff_equation, constant_values, initial_conditions, lr, n_epochs, optimizer_name, lambda_pin, lambda_ic, lambda_bc)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m--> 854\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/optim/optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m             )\n\u001b[0;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/optim/lbfgs.py:450\u001b[0m, in \u001b[0;36mLBFGS.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_iter \u001b[38;5;241m!=\u001b[39m max_iter:\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;66;03m# re-evaluate function only if not in last iteration\u001b[39;00m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;66;03m# the reason we do this: in a stochastic setting,\u001b[39;00m\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;66;03m# no use to re-evaluate that function here\u001b[39;00m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 450\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    451\u001b[0m     flat_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gather_flat_grad()\n\u001b[1;32m    452\u001b[0m     opt_cond \u001b[38;5;241m=\u001b[39m flat_grad\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m tolerance_grad\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Physic-Informed-Neural-Networks/Notebooks/../Scripts/PINN_moredim.py:839\u001b[0m, in \u001b[0;36mPINN_inference.train.<locals>.closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    836\u001b[0m loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m lambda_ic \u001b[38;5;241m*\u001b[39m initial_conditions_loss\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m diff_equation\u001b[38;5;241m.\u001b[39mdx:\n\u001b[0;32m--> 839\u001b[0m     boundary_conditions_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboundary_conditions_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    840\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m lambda_bc \u001b[38;5;241m*\u001b[39m boundary_conditions_loss\n\u001b[1;32m    842\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Documents/Physic-Informed-Neural-Networks/Notebooks/../Scripts/PINN_moredim.py:694\u001b[0m, in \u001b[0;36mPINN_inference.boundary_conditions_loss\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bc, mask \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mboundary_conditions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mboundary_masks):\n\u001b[1;32m    693\u001b[0m     bc_class \u001b[38;5;241m=\u001b[39m BoundaryCondition(bc, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstant_values)\n\u001b[0;32m--> 694\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mbc_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgive_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Documents/Physic-Informed-Neural-Networks/Notebooks/../Scripts/PINN_moredim.py:519\u001b[0m, in \u001b[0;36mBoundaryCondition.give_value\u001b[0;34m(self, temps, ts, mask)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocal_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ts[mask \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m][:, \u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m    517\u001b[0m \u001b[38;5;66;03m# Esto depende de que derivada esté calculando\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m dx \u001b[38;5;241m=\u001b[39m calculate_derivative(temps, ts, \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morders\u001b[49m\u001b[43m)\u001b[49m, idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ts\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    521\u001b[0m     dy \u001b[38;5;241m=\u001b[39m calculate_derivative(temps, ts, \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morders), idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "pinn_inf_model.train(\n",
    "    data=data,\n",
    "    diff_equation=diff_equation,\n",
    "    constant_values=diff_equation.constants,\n",
    "    initial_conditions=initial_conditions,\n",
    "    lr=lr,\n",
    "    n_epochs=n_epochs,\n",
    "    optimizer_name=optimizer,\n",
    "    lambda_pin=lambda_pin,\n",
    "    lambda_ic=lambda_ic,\n",
    "    lambda_bc=lambda_bc,\n",
    ")\n",
    "\n",
    "for constant in pinn_inf_model.params:\n",
    "    print(constant, getattr(pinn_inf_model, constant).item())\n",
    "\n",
    "\n",
    "# Plot the results\n",
    "if diff_equation.dy:\n",
    "    pinn_inf_model.plot_2d(data, plate_length, max_iter_time)\n",
    "elif diff_equation.dx and not diff_equation.dy:\n",
    "    pinn_inf_model.plot_solution(data)\n",
    "elif not diff_equation.dx:\n",
    "    pinn_inf_model.plot(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_t = np.linspace(0, T, max_iter_time)\n",
    "\n",
    "# u_pred = pinn_inf_model(data[2]).reshape(len(train_t), plate_length, plate_length).detach().numpy()\n",
    "# u_true = data[3].reshape(len(train_t), plate_length, plate_length).detach().numpy()\n",
    "# t = -1\n",
    "\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "# ax1, ax2 = axs\n",
    "\n",
    "# im1 = ax1.imshow(u_pred[t, :, :], cmap=plt.cm.jet, vmin=0, vmax=1)\n",
    "# im2 = ax2.imshow(u_true[t, :, :], cmap=plt.cm.jet, vmin=0, vmax=1)\n",
    "\n",
    "# # Add colorbars to both subplots\n",
    "# fig.colorbar(im1, ax=ax1)\n",
    "# fig.colorbar(im2, ax=ax2)\n",
    "\n",
    "# # Set initial titles and labels\n",
    "# ax1.set_title(f'Predicted Temperature at t = {0.1 * (t % max_iter_time)}')\n",
    "# ax1.set_xlabel('x')\n",
    "# ax1.set_ylabel('y')\n",
    "\n",
    "# ax2.set_title(f'True Temperature at t = {0.1 * (t % max_iter_time)}')\n",
    "# ax2.set_xlabel('x')\n",
    "# ax2.set_ylabel('y')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the function has been learnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if func_to_optimize:\n",
    "    temps = pinn_inf_model(data[2])\n",
    "    data[2].requires_grad = True\n",
    "    P_stack_dT = diff_equation()(data[2], temps).detach().numpy()\n",
    "\n",
    "    if not diff_equation.dx:\n",
    "        plt.plot(data[2].detach().numpy(), P_stack_dT, 'g--', label='p_stack - dT')\n",
    "        plt.plot(data[2].detach().numpy(), [0 for _ in range(len(data[2].detach().numpy()))], 'r--', label='0')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    else:\n",
    "        # Crear Scatter3d para datos de entrenamiento y prueba\n",
    "        num_test_divisions = int(np.sqrt(len(P_stack_dT)))\n",
    "        t_test = np.linspace(0, data[2][-1, 0].item(), num_test_divisions)\n",
    "        x_test = np.linspace(0, data[2][-1, 1].item(), num_test_divisions)\n",
    "        u_test = P_stack_dT.reshape((num_test_divisions, num_test_divisions))\n",
    "        scatter_test = go.Scatter3d(\n",
    "            x=data[2][:, 1].detach().numpy(),\n",
    "            y=data[2][:, 0].detach().numpy(),\n",
    "            z=P_stack_dT[:, 0],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=4, opacity=0.5, color=\"blue\"),\n",
    "            name=\"test Data\",\n",
    "        )\n",
    "\n",
    "        y_pred = P_stack_dT\n",
    "        u_test = y_pred.reshape((num_test_divisions, num_test_divisions))\n",
    "        scatter_pred = go.Scatter3d(\n",
    "            x=data[2][:, 1].detach().numpy(),\n",
    "            y=data[2][:, 0].detach().numpy(),\n",
    "            z=y_pred[:, 0],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=2, opacity=0.35, color=\"red\"),\n",
    "            name=\"Test Data\",\n",
    "        )\n",
    "\n",
    "        # Crear la superficie para la función subyacente\n",
    "        surface_true = go.Surface(\n",
    "            x=t_test,\n",
    "            y=x_test,\n",
    "            z=u_test,\n",
    "            opacity=0.5,\n",
    "            colorscale=\"Blues\",\n",
    "            showscale=False,\n",
    "            name=\"True Function\",\n",
    "        )\n",
    "        surface_pred = go.Surface(\n",
    "            x=t_test,\n",
    "            y=x_test,\n",
    "            z=u_test,\n",
    "            opacity=0.5,\n",
    "            colorscale=\"Blues\",\n",
    "            showscale=False,\n",
    "            name=\"True Function\",\n",
    "        )\n",
    "\n",
    "        # Crear el gráfico\n",
    "        fig = go.Figure(data=[scatter_test, scatter_pred, surface_true, surface_pred])\n",
    "        fig.update_layout(\n",
    "            scene=dict(\n",
    "                xaxis_title=\"t\",\n",
    "                yaxis_title=\"x\",\n",
    "                zaxis_title=\"u(t,x)\",\n",
    "                aspectmode=\"cube\",\n",
    "            ),\n",
    "            width=1000,  # Cambia el ancho de la figura\n",
    "            height=800,\n",
    "            legend=dict(x=-0.1, y=1.0, font=dict(size=16)),\n",
    "        )  # Ajusta el tamaño del texto de la leyenda\n",
    "        fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
